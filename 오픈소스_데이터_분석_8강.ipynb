{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/youlee203knou/Data-Analysis-with-Open-Source/blob/main/%EC%98%A4%ED%94%88%EC%86%8C%EC%8A%A4_%EB%8D%B0%EC%9D%B4%ED%84%B0_%EB%B6%84%EC%84%9D_8%EA%B0%95.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJ-_K7V9snHK"
      },
      "source": [
        "# 오픈소스 기반 데이터 분석 8강"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 분석 방법론"
      ],
      "metadata": {
        "id": "xy-q5BlU48cP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iUhflCxPcH0"
      },
      "source": [
        "## 8-1 통계적 모형을 활용한 분석 (statsmodels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vsS87Vx9dV6z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd8fdccf-8f27-4511-838e-7d59caf8d32f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   R-squared:                       0.977\n",
            "Model:                            OLS   Adj. R-squared:                  0.975\n",
            "Method:                 Least Squares   F-statistic:                     345.0\n",
            "Date:                Sun, 12 Oct 2025   Prob (F-statistic):           7.28e-08\n",
            "Time:                        03:43:14   Log-Likelihood:                -12.020\n",
            "No. Observations:                  10   AIC:                             28.04\n",
            "Df Residuals:                       8   BIC:                             28.65\n",
            "Df Model:                           1                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "Intercept      1.7622      0.615      2.866      0.021       0.344       3.180\n",
            "X              1.8406      0.099     18.574      0.000       1.612       2.069\n",
            "==============================================================================\n",
            "Omnibus:                        5.058   Durbin-Watson:                   1.207\n",
            "Prob(Omnibus):                  0.080   Jarque-Bera (JB):                1.191\n",
            "Skew:                          -0.012   Prob(JB):                        0.551\n",
            "Kurtosis:                       1.309   Cond. No.                         13.7\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "# statsmodels의 formula api 임포트\n",
        "import statsmodels.formula.api as smf\n",
        "\n",
        "## 난수 시드 설정\n",
        "random.seed(1)\n",
        "\n",
        "## 데이터 생성\n",
        "X = list(range(1, 11))\n",
        "y = [2*x + 1 + random.gauss(0, 1) for x in X]\n",
        "#x값을 가지고 올 때마다 y값을 새롭게 작\n",
        "\n",
        "## 데이터프레임 생성\n",
        "data = pd.DataFrame({'X': X, 'y': y})\n",
        "\n",
        "## OLS(최소 제곱법) 선형회귀 모델 생성 및 학습\n",
        "## 'y'를 종속 변수로 하고 다른 특성(X)을 독립 변수로 사용\n",
        "model = smf.ols(formula='y ~ X', data=data).fit()\n",
        "#1 smf.ols(formula='종속변수 ~ 독립변수')\n",
        "#1> X값을 가지고 y를 모델링하는 선형회귀모델을 OLS 방법으로 만들어라\n",
        "\n",
        "## 모델 요약 결과 출력\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "R-squared 값이 1에 가까울수록 정확하게 데이터를 모델이 모사했다."
      ],
      "metadata": {
        "id": "LzUmsWbIj5HI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEYBAflNPcH6"
      },
      "source": [
        "## 8-2 기계학습을 활용한 분석 (scikit-learn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ptis5NADdZbj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f3cfbe9-a2f2-4211-83a5-3d0180a7bfa6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9707602339181286\n"
          ]
        }
      ],
      "source": [
        "# scikit-learn의 앙상블(ensemble) 알고리즘 중 RandomForestClassifier 임포트\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# 모델 평가를 위한 데이터 분할(split) 함수 임포트\n",
        "from sklearn.model_selection import train_test_split\n",
        "# 모델의 정확도(accuracy)를 측정하는 함수 임포트\n",
        "from sklearn.metrics import accuracy_score\n",
        "# 예제 데이터셋(유방암 데이터) 로드 함수 임포트\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "## 데이터 로드 및 분할\n",
        "cancer = load_breast_cancer()\n",
        "X, y = cancer.data, cancer.target\n",
        "\n",
        "## 학습/테스트 데이터셋 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "## 랜덤 포레스트 모델 생성 및 학습\n",
        "model = RandomForestClassifier()\n",
        "#모델학습\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "## 예측 및 정확도 평가\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "결과 = 96퍼센트의 정확도를 보여줌\n",
        "\n",
        "RandomforestClassifier : classifier가 굉장히 많이 모여져 있는, 예측할 때 복수의 사람들에게 물어봐서 종합적인 결과를 예측한다.\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=100)\n",
        "100개의 모델을 만들어서 물어볼 것이다.\n",
        "\n",
        "n_estimators는 모델의 갯수를 조절할 수 있는 옵션\n",
        "\n"
      ],
      "metadata": {
        "id": "_scxr-e-logM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WvneUhOPcH9"
      },
      "source": [
        "## 8-3 딥러닝을 활용한 분석 (tensorflow)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ze_9DpFddcTQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71cf4334-a276-4f0f-c0ff-9f2d1ffa3d97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 1us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_160_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
            "Epoch 1/3\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 33ms/step - accuracy: 0.6884 - loss: 0.9071 - val_accuracy: 0.8183 - val_loss: 0.5356\n",
            "Epoch 2/3\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 19ms/step - accuracy: 0.8245 - loss: 0.5174 - val_accuracy: 0.8140 - val_loss: 0.5420\n",
            "Epoch 3/3\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 19ms/step - accuracy: 0.8372 - loss: 0.4748 - val_accuracy: 0.8249 - val_loss: 0.5041\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 30ms/step\n",
            "\n",
            "Test Accuracy: 0.819599986076355\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.87      0.84      1000\n",
            "           1       0.90      0.91      0.90      1000\n",
            "           2       0.74      0.79      0.76      1000\n",
            "           3       0.73      0.63      0.68      1000\n",
            "           4       0.72      0.82      0.77      1000\n",
            "           5       0.79      0.74      0.77      1000\n",
            "           6       0.91      0.81      0.86      1000\n",
            "           7       0.81      0.88      0.84      1000\n",
            "           8       0.87      0.87      0.87      1000\n",
            "           9       0.93      0.87      0.90      1000\n",
            "\n",
            "    accuracy                           0.82     10000\n",
            "   macro avg       0.82      0.82      0.82     10000\n",
            "weighted avg       0.82      0.82      0.82     10000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "# 딥러닝 분석을 위한 tensorflow 임포트\n",
        "# 여러가지 관점에 따른 측정을 위해 classification_report\n",
        "import tensorflow as tf\n",
        "\n",
        "## CIFAR-10 데이터셋 로드 및 전처리\n",
        "# 여러 그림이 주어졌을때 딥러닝이 그림의 종류를 맞출 수 있는지 학습 중\n",
        "# cpu로는 처리가 오래걸리니까 gpu로 변경해서 런타임을 실행해주는게 좋다\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "x_train, x_test = x_train/255.0, x_test/255.0\n",
        "\n",
        "## MobileNetV2 기반 모델 구축\n",
        "# 기존에 학습이 되어있는 모델을 이용해서 특정 상황에 맞춰서 특성화시킨다\n",
        "base_model = tf.keras.applications.MobileNetV2(weights='imagenet', include_top=False, input_shape=(160, 160, 3))\n",
        "base_model.trainable = False\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Resizing(160, 160),\n",
        "    base_model,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "## 모델 컴파일\n",
        "# 모델 학습 과정1 > 방법론2\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "## 모델 학습\n",
        "model.fit(x_train, y_train, epochs=3, validation_split=0.2)\n",
        "\n",
        "## 예측 및 성능 평가\n",
        "y_pred = tf.argmax(model.predict(x_test), axis=1)\n",
        "print(\"\\nTest Accuracy:\", model.evaluate(x_test, y_test, verbose=0)[1])\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "프리시전, recall, f1-score에 대해서는 교재에 있는 설명 확인\n",
        "\n",
        "gpu는 사용하는 시간에 제한이 있으므로 평소에는 cpu로 사용\n",
        "\n",
        "gpu는 딥러닝하러때만 사용"
      ],
      "metadata": {
        "id": "D8e_OKIdjVg_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNB7tpokPcH_"
      },
      "source": [
        "## 8-4 EDA 예시"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EDA 데이터 분석을 할때 어떤 모델을 사용해야겠다라는 전략을 세울 때 데이터를 넓은 관점에서 크게 볼때 사용하는 과정"
      ],
      "metadata": {
        "id": "FOdWwTqTpbdk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhF8O0CkdgwC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_diabetes\n",
        "\n",
        "## 당뇨병 데이터셋 로드 및 데이터프레임 생성\n",
        "diabetes = load_diabetes()\n",
        "df = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\n",
        "df['target'] = diabetes.target\n",
        "\n",
        "## dataframe의 describe를 이용하여 기본 통계량 출력\n",
        "\n",
        "## 상관 행렬 시각화\n",
        "plt.figure(figsize=(12,8))\n",
        "# dataframe의 각 열(변수)들 간의 상관 계수(correlation coefficient)를 계산하고 corr_matrix로 저장\n",
        "# seaborn으로 corr_matrix를 heatmap으로 시각화\n",
        "plt.title('Diabetes Dataset Correlation Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuoWU4FFPcIA"
      },
      "source": [
        "## 8-5 기술통계량 분석"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLSGHj3ddkWf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "## 아이리스 데이터셋 로드\n",
        "df = sns.load_dataset('iris')\n",
        "\n",
        "# 기술 통계량\n",
        "print(\"=== 기본 통계량 ===\")\n",
        "print(df.describe())\n",
        "\n",
        "# 데이터 미리보기\n",
        "print(\"\\n=== 데이터 미리보기 ===\")\n",
        "\n",
        "# 그룹별 통계정보\n",
        "print(\"\\n=== 품종별 평균값 ===\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFOLMIFtPcID"
      },
      "source": [
        "## 8-6 데이터 시각화 분석"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6b3cp7UPcID"
      },
      "outputs": [],
      "source": [
        "# 한글 처리를 위한 matplotlib 설정 (1)\n",
        "\n",
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache –fv\n",
        "!rm ~/.cache/matplotlib -rf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGWiB2Z-PcIE"
      },
      "source": [
        "- 리소스 재시작"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sV1HYIOBPcIE"
      },
      "outputs": [],
      "source": [
        "# 한글 처리를 위한 matplotlib 설정 (2)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rc('font', family='NanumBarunGothic')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekh3vzrsdrBd"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "## 아이리스 데이터셋 로드\n",
        "df = sns.load_dataset('iris')\n",
        "\n",
        "## 서브플롯 설정\n",
        "plt.figure(figsize=(9, 12))\n",
        "plt.suptitle('Iris 데이터셋 시각화', y=1.02, fontsize=14)\n",
        "\n",
        "## 첫 번째 서브플롯: 꽃잎 길이 분포 (히스토그램)\n",
        "plt.subplot(4, 1, 1)\n",
        "# seaborn을 이용하여 petal_length를 10개 구간으로 나누어 히스토그램 표시\n",
        "plt.title('꽃잎 길이 분포')\n",
        "plt.xlabel('꽃잎 길이 (cm)')\n",
        "\n",
        "## 두 번째 서브플롯: 꽃잎 길이 vs 너비 (산점도)\n",
        "plt.subplot(4, 1, 2)\n",
        "species_list = df['species'].unique()\n",
        "colors = {'setosa':'red', 'versicolor':'green', 'virginica':'blue'}\n",
        "\n",
        "for species in species_list:\n",
        "    species_data = df[df['species'] == species]\n",
        "    # matplotlib를 이용하여 길이, 넓이를 산점도로 표시\n",
        "plt.title('꽃잎 길이 vs 너비')\n",
        "plt.xlabel('꽃잎 길이 (cm)')\n",
        "plt.ylabel('꽃잎 너비 (cm)')\n",
        "plt.legend()\n",
        "\n",
        "## 세 번째 서브플롯: 품종별 꽃받침 길이 (박스플롯)\n",
        "plt.subplot(4, 1, 3)\n",
        "# seaborn을 이용하여 품종 별 꽃받침 길이를 박스플롯으로 표시\n",
        "plt.title('품종별 꽃받침 길이 비교')\n",
        "plt.xlabel('품종')\n",
        "plt.ylabel('꽃받침 길이 (cm)')\n",
        "\n",
        "## 네 번째 서브플롯: 숫자형 특성 간 상관관계 (히트맵)\n",
        "plt.subplot(4, 1, 4)\n",
        "numeric_df = df.select_dtypes(include='number')\n",
        "corr = numeric_df.corr()\n",
        "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('숫자형 특성 간 상관관계')\n",
        "\n",
        "## 레이아웃 조정 및 그래프 표시\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1H7M1jS8PcIF"
      },
      "source": [
        "## 8-7 자동화된 EDA 도구"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ydata_profiling"
      ],
      "metadata": {
        "id": "HxhXsvwlQp9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXR2-oPkdrmN"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "from ydata_profiling import ProfileReport\n",
        "\n",
        "## 아이리스 데이터셋 로드\n",
        "df = sns.load_dataset('iris')\n",
        "\n",
        "## 데이터 프로파일링 보고서 생성\n",
        "\n",
        "## HTML 파일로 보고서 저장\n",
        "\n",
        "## 보고서 표시 (Jupyter Notebook 환경에서 보고서가 바로 표시됨)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}